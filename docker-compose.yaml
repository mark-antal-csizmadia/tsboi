version: '1'
# partly based on: https://github.com/aganse/docker_mlflow_db/tree/master

services:
  db:
    restart: always
    image: postgres:latest
    container_name: db
    expose:
        - ${DB_PORT:-5432}
    networks:
        - backend
    environment:
        - POSTGRES_DB=${PG_DATABASE}
        - POSTGRES_USER=${PG_USER}
        - POSTGRES_PASSWORD=${PG_PASSWORD}
    volumes:
        - db_datapg:/var/lib/postgresql/data

  mlflow-server:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile-mlflow-server
    image: mlflow_server
    container_name: mlflow_server
    expose:
      - 5000
    networks:
      - frontend
      - backend
    environment:
      - BACKEND=postgresql://${PG_USER}:${PG_PASSWORD}@db:${DB_PORT:-5432}/${PG_DATABASE}
      - ARTIFACTS=/mlruns
      # For artifact store in AWS S3 (note boto was installed in container):
      #  - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      #  - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      #  - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      #  - ARTIFACTS="s3://mlflow_bucket/my_mlflow_dir/"
    volumes:
      - type: bind
        source: mlrun_data
        target: /mlruns
    command:
      - sh
      - -c
      - mlflow server
        --port 5000
        --host 0.0.0.0
        --backend-store-uri $${BACKEND}
        --artifacts-destination $${ARTIFACTS}
    depends_on:
      - db

  nginx:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile-nginx
    image: mlflow_nginx
    container_name: mlflow_nginx
    ports:
      - "${MLFLOW_PORT:-5000}:80"
    networks:
      - frontend
    depends_on:
      - mlflow-server

  fit_xgb:
    container_name: fit_xgb
    build:
      context: .
      dockerfile: Dockerfile
    image: tsboi
    depends_on:
      - db
      - mlflow-server
      - nginx
    environment:
      MLFLOW_TRACKING_URI: http://mlflow-server:5000
      DATASET_DIGEST: 9c3bf8a86cf74d9f84fd38d86087314e70766a95
    networks:
      - backend
    volumes:
      - type: bind
        source: ./data
        target: /app/data
      - type: bind
        source: ./models
        target: /app/models
      - type: bind
        source: ./optuna_studies
        target: /app/optuna_studies
    deploy:
      resources:
        limits:
          cpus: '6.00'
          memory: 8000M
        reservations:
          cpus: '4.00'
          memory: 4000M
    command: python3 examples/fit_xgb.py --study_name cool_neurai_study --random_state 42
    links:
      - "mlflow-server:mlflow-server"

  hp_search_xgb:
    container_name: hp_search_xgb
    build:
      context: .
      dockerfile: Dockerfile
    image: tsboi
    depends_on:
      - db
      - mlflow-server
      - nginx
    environment:
      MLFLOW_TRACKING_URI: http://mlflow-server:5000
      DATASET_DIGEST: 9c3bf8a86cf74d9f84fd38d86087314e70766a95
    networks:
      - backend
    volumes:
      - type: bind
        source: ./data
        target: /app/data
      - type: bind
        source: ./models
        target: /app/models
      - type: bind
        source: ./optuna_studies
        target: /app/optuna_studies
    deploy:
      resources:
        limits:
          cpus: '6.00'
          memory: 8000M
        reservations:
          cpus: '4.00'
          memory: 4000M
    # command: python3 examples/hp_search_xgb.py --n_trials 2 --study_name cool_neurai_study --random_state 42
    command: python3 examples/hp_search_xgb.py --n_trials 2 --random_state 42
    links:
      - "mlflow-server:mlflow-server"

  tests:
    container_name: tests
    build:
      context: .
      dockerfile: Dockerfile
    image: tsboi
    depends_on:
      - db
    command: python3 -m pytest -s --postgres_host=postgres
    networks:
      - backend
    links:
      - "db:postgres"


networks:
    backend:
        driver: bridge
    frontend:
        driver: bridge

volumes:
    db_datapg:
    mlrun_data:
    condenv:
    data:
    models:
    optuna_studies: